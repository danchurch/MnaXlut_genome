{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstructing a <i>Mimulus naiandinus</i> genome from hybrid genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"contents\">Table o' contents</a>\n",
    "\n",
    "[Look at read qualities](#read_quality)\n",
    "\n",
    "[Align our reads to the reference genome](#align)\n",
    "\n",
    "[Filtering and Processing alignments](#FandP)\n",
    "  - [Convert SAMs to BAMs](#sam2bam)\n",
    "  - [Reorder alignments to reference](#reorder)\n",
    "  - [DeDuplicate reads](#dedupe)\n",
    "  - [Merging BAM files](#mergeBAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"read_quality\">Look at read qualities</a>\n",
    "\n",
    "Let's use fastx tools to take a look at the average read qualities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## path to our fastq files\n",
    "fpath='/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastx requires that we calculate the statistics first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S1_S16_L002_R1_001.fastq\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S1_S16_L002_R1_001.fastq done!\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S2_S17_L002_R1_001.fastq\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S2_S17_L002_R1_001.fastq done!\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S3_S18_L002_R1_001.fastq\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S3_S18_L002_R1_001.fastq done!\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S4_S19_L002_R1_001.fastq\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S4_S19_L002_R1_001.fastq done!\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S5_S20_L002_R1_001.fastq\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S5_S20_L002_R1_001.fastq done!\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S6_S21_L002_R1_001.fastq\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S6_S21_L002_R1_001.fastq done!\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/merged.fastq\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/merged.fastq done!\n"
     ]
    }
   ],
   "source": [
    "for i in $fpath*\"fastq\"\n",
    "do\n",
    "echo $i\n",
    "$ftd\"fastx_quality_stats\" -Q33 -i $i -o $i\"-Stats.txt\"\n",
    "echo $i done!\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S1_S16_L002_R1_001.fastq-Stats.txtquality.eps\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S2_S17_L002_R1_001.fastq-Stats.txtquality.eps\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S3_S18_L002_R1_001.fastq-Stats.txtquality.eps\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S4_S19_L002_R1_001.fastq-Stats.txtquality.eps\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S5_S20_L002_R1_001.fastq-Stats.txtquality.eps\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/JP-S6_S21_L002_R1_001.fastq-Stats.txtquality.eps\n",
      "/Users/danthomas/Documents/naiandinus_gen/for_dan/Cooley_3315_160429B1/merged.fastq-Stats.txtquality.eps\n"
     ]
    }
   ],
   "source": [
    "for i in $fpath*Stats.txt; do\n",
    "fastq_quality_boxplot_graph.sh -i $i -o $i\"quality.eps\" -p\n",
    "echo $i\"quality.eps\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these look like? Here is our merged file, that has all of the reads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![read_quality](merged.fastq-Stats.txtquality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great, high quality reads, with almost no variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"align\">Align our reads to the reference genome</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use [bowtie2](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml) to align our reads to our reference genome. The reference genome needs to be indexed in the way that bowtie2 wants, first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"Mlu.*.bt2\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 4 (one in 16)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Max bucket size: default\n",
      "  Max bucket size, sqrt multiplier: default\n",
      "  Max bucket size, len divisor: 4\n",
      "  Difference-cover sample period: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  /Users/danthomas/Documents/naiandinus_gen/Luteus_genome/Mimulus_luteus.fasta\n",
      "Building a SMALL index\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:09\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:04\n",
      "bmax according to bmaxDivN setting: 98519930\n",
      "Using parameters --bmax 73889948 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 73889948 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:08\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:03\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:03\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 3.9408e+08 (target: 73889947)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 1\n",
      "  No samples; assembling all-inclusive block\n",
      "  Sorting block of length 394079723 for bucket 1\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:03:58\n",
      "Returning block of 394079724 for bucket 1\n",
      "Exited Ebwt loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 128231942\n",
      "fchr[G]: 196999917\n",
      "fchr[T]: 265812832\n",
      "fchr[$]: 394079723\n",
      "Exiting Ebwt::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 136028617 bytes to primary EBWT file: Mlu.1.bt2\n",
      "Wrote 98519936 bytes to secondary EBWT file: Mlu.2.bt2\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from Ebwt constructor\n",
      "Headers:\n",
      "    len: 394079723\n",
      "    bwtLen: 394079724\n",
      "    sz: 98519931\n",
      "    bwtSz: 98519931\n",
      "    lineRate: 6\n",
      "    offRate: 4\n",
      "    offMask: 0xfffffff0\n",
      "    ftabChars: 10\n",
      "    eftabLen: 20\n",
      "    eftabSz: 80\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 24629983\n",
      "    offsSz: 98519932\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideBwtSz: 48\n",
      "    sideBwtLen: 192\n",
      "    numSides: 2052499\n",
      "    numLines: 2052499\n",
      "    ebwtTotLen: 131359936\n",
      "    ebwtTotSz: 131359936\n",
      "    color: 0\n",
      "    reverse: 0\n",
      "Total time for call to driver() for forward index: 00:05:25\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:05\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:03\n",
      "  Time to reverse reference sequence: 00:00:00\n",
      "bmax according to bmaxDivN setting: 98519930\n",
      "Using parameters --bmax 73889948 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 73889948 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:07\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:03\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:03\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 3.9408e+08 (target: 73889947)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering Ebwt loop\n",
      "Getting block 1 of 1\n",
      "  No samples; assembling all-inclusive block\n",
      "  Sorting block of length 394079723 for bucket 1\n",
      "  (Using difference cover)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/bowtie2-build\", line 86, in <module>\n",
      "    main()\n",
      "  File \"/usr/local/bin/bowtie2-build\", line 83, in main\n",
      "    subprocess.call(argv)\n",
      "  File \"/Users/danthomas/anaconda3/lib/python3.6/subprocess.py\", line 269, in call\n",
      "    return p.wait(timeout=timeout)\n",
      "  File \"/Users/danthomas/anaconda3/lib/python3.6/subprocess.py\", line 1457, in wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/Users/danthomas/anaconda3/lib/python3.6/subprocess.py\", line 1404, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "bowtie2-build -f /Users/danthomas/Documents/naiandinus_gen/Luteus_genome/Mimulus_luteus.fasta Mlu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can loop through our fastq files and do alignments against this reference genome. For the moment, we'll do these as individual alignments of the six bins of phenotypes assigned by Arielle and Josh. This results in a sequence alignment map (SAM) for each of the six."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/danthomas/Documents/naiandinus_gen/Luteus_genome\n",
    "\n",
    "for i in $fpath*001.fastq; do\n",
    "    j=$(basename $i)\n",
    "    k=${j/fastq/sam}\n",
    "    bowtie2 --local  -x Mlu -U $i -S /Users/danthomas/Documents/naiandinus_gen/SAM/$k \\\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56034871 reads; of these:\n",
      "  56034871 (100.00%) were unpaired; of these:\n",
      "    7893494 (14.09%) aligned 0 times\n",
      "    11729089 (20.93%) aligned exactly 1 time\n",
      "    36412288 (64.98%) aligned >1 times\n",
      "85.91% overall alignment rate\n",
      "68049510 reads; of these:\n",
      "  68049510 (100.00%) were unpaired; of these:\n",
      "    7592098 (11.16%) aligned 0 times\n",
      "    14879687 (21.87%) aligned exactly 1 time\n",
      "    45577725 (66.98%) aligned >1 times\n",
      "88.84% overall alignment rate\n",
      "60681218 reads; of these:\n",
      "  60681218 (100.00%) were unpaired; of these:\n",
      "    9222716 (15.20%) aligned 0 times\n",
      "    12679236 (20.89%) aligned exactly 1 time\n",
      "    38779266 (63.91%) aligned >1 times\n",
      "84.80% overall alignment rate\n",
      "55885597 reads; of these:\n",
      "  55885597 (100.00%) were unpaired; of these:\n",
      "    7485075 (13.39%) aligned 0 times\n",
      "    11651355 (20.85%) aligned exactly 1 time\n",
      "    36749167 (65.76%) aligned >1 times\n",
      "86.61% overall alignment rate\n",
      "67627796 reads; of these:\n",
      "  67627796 (100.00%) were unpaired; of these:\n",
      "    15149703 (22.40%) aligned 0 times\n",
      "    13937577 (20.61%) aligned exactly 1 time\n",
      "    38540516 (56.99%) aligned >1 times\n",
      "77.60% overall alignment rate\n",
      "66654520 reads; of these:\n",
      "  66654520 (100.00%) were unpaired; of these:\n",
      "    9078782 (13.62%) aligned 0 times\n",
      "    14502639 (21.76%) aligned exactly 1 time\n",
      "    43073099 (64.62%) aligned >1 times\n",
      "86.38% overall alignment rate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat bowtie_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for these alignments, as a whole:\n",
    "\n",
    "real    565m3.770s  \n",
    "user    554m22.225s  \n",
    "sys     4m27.857s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These SAM files look like this, a header that lists out the lengths of our scaffolds, and a body that is a long list of where the various reads were assigned on the reference genome, with a mapq quality score for the confidence in the placement of this read on the reference genome, the quality of the basecalls, other good stuff. More info <a href=\"https://en.wikipedia.org/wiki/SAM_(file_format)\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@HD\tVN:1.0\tSO:unsorted\n",
      "@SQ\tSN:lcl|scaffold_32\tLN:817265\n",
      "@SQ\tSN:lcl|scaffold_21\tLN:849581\n",
      "@SQ\tSN:lcl|scaffold_14\tLN:884134\n",
      "@SQ\tSN:lcl|scaffold_37\tLN:783220\n",
      "@SQ\tSN:lcl|scaffold_23\tLN:851886\n",
      "@SQ\tSN:lcl|scaffold_8\tLN:980590\n",
      "@SQ\tSN:lcl|scaffold_9\tLN:976062\n",
      "@SQ\tSN:lcl|scaffold_33\tLN:797088\n",
      "@SQ\tSN:lcl|scaffold_38\tLN:791999\n"
     ]
    }
   ],
   "source": [
    "head JP-S6_S21_L002_R1_001.sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K00282:27:HC3GVBBXX:2:2228:30959:49194\t0\tlcl|scaffold_606\t126980\t44\t48M3S\t*\t0\t0\tTTGAGCCTTTTGTAGTAGGATTTATGAATTTCTCTGGAGCTTTATTAGACT\tAAFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJ\tAS:i:96\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:48\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:31081:49194\t16\tlcl|scaffold_24\t610319\t11\t1S33M1I14M2S\t*\t0\t0\tCCATGTTGGAGTCCGAGTTTTGGAATGTTGCATGAAATAAGAATTGTAGAC\tJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFFFAA\tAS:i:78\tXS:i:76\tXN:i:0\tXM:i:1\tXO:i:1\tXG:i:1\tNM:i:2\tMD:Z:30G16\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:31284:49194\t16\tlcl|scaffold_1046\t13016\t17\t51M\t*\t0\t0\tCCGCGATTTCTCTCGATTTCTAATGCAATACACAAATCAATTGGTTCTGTT\tJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFFFAA\tAS:i:94\tXS:i:80\tXN:i:0\tXM:i:1\tXO:i:0\tXG:i:0\tNM:i:1\tMD:Z:24T26\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:31527:49194\t0\tlcl|scaffold_448\t249337\t31\t51M\t*\t0\t0\tAGTAGCATGGGCTGCAATAAAGGCCCGGTGTCATTGTGTTAATAAAAAATG\tAAFFFJJJJJJJJJJJJ<JJJJJJJJJJJJJJFJJJJJJJJJJJJJJJJJJ\tAS:i:102\tXS:i:94\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:51\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:31568:49194\t4\t*\t0\t0\t*\t*\t0\t0\tGGATCTTGGGTAGAGACGGGTGATATTTTAGTAGGTAAATTAACGCCCCAA\tAAFFFJJJJJJJJJJJJJJJJJJJJJJJ<JJFAFJFJJJJJJJJJJJJJJJ\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:31730:49194\t0\tlcl|scaffold_1610\t11334\t44\t51M\t*\t0\t0\tTGGATTATTAATCCAAATTCAATCCAAATTTCAGTTTAAAACTTACTTAAT\tAAAFFJJJJJJJJFJJJJJJJJJFJFFFJJJJJJJJJJJFJJFJJAJJJJJ\tAS:i:102\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:51\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:31771:49194\t16\tlcl|scaffold_1142\t32734\t1\t51M\t*\t0\t0\tTTGAGTTGTGAGAAACGAGCGAGTAAAGAACTAACGAACTTAAGCTGTTGG\tJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJ<JJJJJJF7JJJFFFAA\tAS:i:102\tXS:i:102\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:51\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:32136:49194\t0\tlcl|scaffold_4\t356623\t1\t48M3S\t*\t0\t0\tAATATATTAGTAAATTGGAAAACTACCAACCATTGATGACAACATACAGAC\tAA-FAJJJJJFJFFFFJJFJJJFJJJJJJJJJJ7JJJJJJJJJJJJJJJJJ\tAS:i:80\tXS:i:80\tXN:i:0\tXM:i:2\tXO:i:0\tXG:i:0\tNM:i:2\tMD:Z:5C25T16\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:32197:49194\t16\tlcl|scaffold_75\t143532\t44\t1S25M1D25M\t*\t0\t0\tTCCTTTCGTATCATTGTGGATGTGAATTGGCTGAATAAAGAGATGAAAGCA\tJJJJJJJJJJJJJJJJJJJJFJJAJJAJJ7FF<JJJJJJJFJJJFJFFFAA\tAS:i:92\tXN:i:0\tXM:i:0\tXO:i:1\tXG:i:1\tNM:i:1\tMD:Z:25^T25\tYT:Z:UU\n",
      "K00282:27:HC3GVBBXX:2:2228:32258:49194\t16\tlcl|scaffold_161\t179975\t44\t3S48M\t*\t0\t0\tTTGTTTCCAATTATTAACAAGAATTTTAAATCTTTATTTCCTGTTTGAGTT\tJJFFJJJJJJJJJJFJJF7JFJJJJFJJJJJJJJJFJJJJJJJJJJFFFAA\tAS:i:96\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:48\tYT:Z:UU\n"
     ]
    }
   ],
   "source": [
    "tail JP-S6_S21_L002_R1_001.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=FandP>Filtering and Processing alignments</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before calling our variants (places where our new genomes are different from the reference), we've got some cleanup to do to our new alignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"sam2bam\">Convert SAMs to BAMs</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For downstream work, we'll work with compressed SAM files, called BAM files. We'll use <a href=\"http://www.htslib.org\">Samtools</a> for this and other tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JP-S1_S16_L002_R1_001.sam\n",
      "JP-S2_S17_L002_R1_001.sam\n",
      "JP-S3_S18_L002_R1_001.sam\n",
      "JP-S4_S19_L002_R1_001.sam\n",
      "JP-S5_S20_L002_R1_001.sam\n",
      "JP-S6_S21_L002_R1_001.sam\n"
     ]
    }
   ],
   "source": [
    "cd /Users/danthomas/Documents/naiandinus_gen/SAM\n",
    "\n",
    "for i in *sam; do\n",
    "    time samtools view $i -bS > ./BAM/${i/sam/bam} && \\\n",
    "    echo $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"reorder\">Reorder alignments to reference</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also necessary to sort the alignments in the order they appear on the reference genome. <a href=\"https://broadinstitute.github.io/picard/\">Picard</a> tools are useful here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/danthomas/Documents/naiandinus_gen/BAM\n",
    "\n",
    "for i in *\n",
    "do \n",
    "    output=\"sortedBAM/\"${i/.bam/.sorted.bam}\n",
    "    picard SortSam I=$i O=$output SORT_ORDER=coordinate && \\\n",
    "    ls $i\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"dedupe\">DeDuplicate reads</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use Picard tools to remove duplicate reads. This has been recommended to me, and it's discussed <a href=\"https://broadinstitute.github.io/picard/command-line-overview.html#MarkDuplicates\">here</a>. \n",
    "\n",
    "I'm a little unclear on this. I can see why removing duplicates is handy.  Dereplicating the redundant information in duplicates makes sense as far as computational expense. But the explanation in picard's manual implies that all duplicates are erroroneous reads, either from bench preps or the cameras of the sequencers - how can this be true? Presumably the same digestion site occurs several times, gets sequenced? Maybe the sites of digestion are random, so it is really unlikely that a sequence would happen twice. If duplicate reads are real (can they be?) aren't we losing converage by removing them?\n",
    "\n",
    "Not sure, anyway, just following orders like a good scientist..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## home for our deduplicated maps:\n",
    "ddm=\"/Users/danthomas/Documents/naiandinus_gen/BAM/dmBAM/\"\n",
    "\n",
    "cd /Users/danthomas/Documents/naiandinus_gen/BAM/sortedBAM\n",
    "\n",
    "for i in *\n",
    "do\n",
    "    output=${i/.sorted.bam/.MD.bam}\n",
    "    echo $output\n",
    "    picard MarkDuplicates \\\n",
    "        I=$i \\\n",
    "        O=$ddm$output \\\n",
    "        M=$output.metrics.txt \\\n",
    "        REMOVE_DUPLICATES=true \\\n",
    "        MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=256 && echo $i\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the last input by asking our computer what kind of load it can handle at the moment, in terms of number of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "ulimit -n "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"readGroups\">Adding read group information to reads</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to merge all of 6 of the genomes, that were binned by phenotype, for the variant calls. Before we do this, we want to retain the information about what phenotype a given read came from. In the fastq files and SAM/BAM files, this information is encoded in the read name. But from here this information is tracked as part of the \"RG\" info, or read group information, in the merged BAM file. Picard tools again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /Users/danthomas/Documents/naiandinus_gen/BAM/dmBAM\n",
    "\n",
    "rgBAMs=\"/Users/danthomas/Documents/naiandinus_gen/BAM/rgBAM/\"\n",
    "\n",
    "touch $rgBAMs\"rglog.txt\"\n",
    "\n",
    "for i in *; do\n",
    "    echo $i >> $rgBAMs\"rglog.txt\"\n",
    "    SM=$(echo $i | sed \"s/.*_S/S/g\" | sed \"s/_L.*//g\")\n",
    "    output=$rgBAMs${i/.MD.bam/.RG.bam}\n",
    "    picard AddOrReplaceReadGroups  I=$i  O=$output  RGPL=illumina  RGPU=indexSEQ  RGID=27  RGLB=A_Library  RGSM=$SM\n",
    "    echo $output >> $rgBAMs\"rglog.txt\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"mergeBAM\">Merging BAM files</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
